{"cells":[{"cell_type":"markdown","metadata":{"id":"p35qYqUBUAoj"},"source":["# Environment setup"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import detectron2.utils.comm as comm\n","from detectron2.config import get_cfg\n","from detectron2.projects.deeplab import add_deeplab_config\n","from detectron2.utils.logger import setup_logger\n","from MODULES.MaskFormer.config import add_mask_former_config"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Loading config MODULES/MaskFormer/configs/custom/MaskAVSL_swin_base.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.\n"]},{"data":{"text/plain":["<Logger MaskAVSL (DEBUG)>"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# Create configs and perform basic setups\n","\n","cfg = get_cfg()\n","add_deeplab_config(cfg)\n","add_mask_former_config(cfg)\n","cfg.set_new_allowed(True)\n","cfg.merge_from_file(\"MODULES/MaskFormer/configs/custom/MaskAVSL_swin_base.yaml\")\n","# cfg.merge_from_list(args.opts)\n","cfg.MODEL.DEVICE = \"cuda:2\"\n","cfg.SOLVER.IMS_PER_BATCH = 4\n","cfg.eval_only = False\n","cfg.freeze()\n","# default_setup(cfg, args)\n","# Setup logger for \"mask_former\" module\n","setup_logger(output=cfg.OUTPUT_DIR, distributed_rank=comm.get_rank(), name=\"MaskAVSL\")"]},{"cell_type":"markdown","metadata":{},"source":["# Trainer"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/envs/GEA/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272168290/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"]},{"name":"stdout","output_type":"stream","text":["221831 of train videos have loaded\n"]}],"source":["from trainer import Trainer\n","\n","trainer = Trainer(cfg)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":["AVSLModel(\n","  (backbone): D2SwinTransformer(\n","    (patch_embed): PatchEmbed(\n","      (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n","      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (pos_drop): Dropout(p=0.0, inplace=False)\n","    (layers): ModuleList(\n","      (0): BasicLayer(\n","        (blocks): ModuleList(\n","          (0): SwinTransformerBlock(\n","            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=128, out_features=384, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=128, out_features=128, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): Identity()\n","            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=128, out_features=512, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=512, out_features=128, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (1): SwinTransformerBlock(\n","            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=128, out_features=384, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=128, out_features=128, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): DropPath(drop_prob=0.013)\n","            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=128, out_features=512, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=512, out_features=128, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","        )\n","        (downsample): PatchMerging(\n","          (reduction): Linear(in_features=512, out_features=256, bias=False)\n","          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (1): BasicLayer(\n","        (blocks): ModuleList(\n","          (0): SwinTransformerBlock(\n","            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=256, out_features=768, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=256, out_features=256, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): DropPath(drop_prob=0.026)\n","            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=256, out_features=1024, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=1024, out_features=256, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (1): SwinTransformerBlock(\n","            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=256, out_features=768, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=256, out_features=256, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): DropPath(drop_prob=0.039)\n","            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=256, out_features=1024, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=1024, out_features=256, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","        )\n","        (downsample): PatchMerging(\n","          (reduction): Linear(in_features=1024, out_features=512, bias=False)\n","          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (2): BasicLayer(\n","        (blocks): ModuleList(\n","          (0): SwinTransformerBlock(\n","            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=512, out_features=512, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): DropPath(drop_prob=0.052)\n","            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (1): SwinTransformerBlock(\n","            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=512, out_features=512, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): DropPath(drop_prob=0.065)\n","            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (2): SwinTransformerBlock(\n","            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=512, out_features=512, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): DropPath(drop_prob=0.078)\n","            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (3): SwinTransformerBlock(\n","            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=512, out_features=512, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): DropPath(drop_prob=0.091)\n","            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (4): SwinTransformerBlock(\n","            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=512, out_features=512, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): DropPath(drop_prob=0.104)\n","            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (5): SwinTransformerBlock(\n","            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=512, out_features=512, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): DropPath(drop_prob=0.117)\n","            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (6): SwinTransformerBlock(\n","            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=512, out_features=512, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): DropPath(drop_prob=0.130)\n","            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (7): SwinTransformerBlock(\n","            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=512, out_features=512, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): DropPath(drop_prob=0.143)\n","            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (8): SwinTransformerBlock(\n","            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=512, out_features=512, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): DropPath(drop_prob=0.157)\n","            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (9): SwinTransformerBlock(\n","            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=512, out_features=512, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): DropPath(drop_prob=0.170)\n","            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (10): SwinTransformerBlock(\n","            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=512, out_features=512, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): DropPath(drop_prob=0.183)\n","            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (11): SwinTransformerBlock(\n","            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=512, out_features=512, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): DropPath(drop_prob=0.196)\n","            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (12): SwinTransformerBlock(\n","            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=512, out_features=512, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): DropPath(drop_prob=0.209)\n","            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (13): SwinTransformerBlock(\n","            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=512, out_features=512, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): DropPath(drop_prob=0.222)\n","            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (14): SwinTransformerBlock(\n","            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=512, out_features=512, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): DropPath(drop_prob=0.235)\n","            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (15): SwinTransformerBlock(\n","            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=512, out_features=512, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): DropPath(drop_prob=0.248)\n","            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (16): SwinTransformerBlock(\n","            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=512, out_features=512, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): DropPath(drop_prob=0.261)\n","            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (17): SwinTransformerBlock(\n","            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=512, out_features=512, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): DropPath(drop_prob=0.274)\n","            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","        )\n","        (downsample): PatchMerging(\n","          (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n","          (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (3): BasicLayer(\n","        (blocks): ModuleList(\n","          (0): SwinTransformerBlock(\n","            (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): DropPath(drop_prob=0.287)\n","            (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (1): SwinTransformerBlock(\n","            (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): DropPath(drop_prob=0.300)\n","            (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (norm0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","    (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","    (norm3): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (pixel_decoder): TransformerEncoderPixelDecoder(\n","    (adapter_1): Conv2d(\n","      128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","      (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n","    )\n","    (layer_1): Conv2d(\n","      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","      (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n","    )\n","    (adapter_2): Conv2d(\n","      256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","      (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n","    )\n","    (layer_2): Conv2d(\n","      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","      (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n","    )\n","    (adapter_3): Conv2d(\n","      512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","      (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n","    )\n","    (layer_3): Conv2d(\n","      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","      (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n","    )\n","    (mask_features): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (input_proj): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (transformer): TransformerEncoderOnly(\n","      (encoder): TransformerEncoder(\n","        (layers): ModuleList(\n","          (0): TransformerEncoderLayer(\n","            (self_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n","            )\n","            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n","            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","            (dropout1): Dropout(p=0.0, inplace=False)\n","            (dropout2): Dropout(p=0.0, inplace=False)\n","          )\n","          (1): TransformerEncoderLayer(\n","            (self_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n","            )\n","            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n","            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","            (dropout1): Dropout(p=0.0, inplace=False)\n","            (dropout2): Dropout(p=0.0, inplace=False)\n","          )\n","          (2): TransformerEncoderLayer(\n","            (self_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n","            )\n","            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n","            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","            (dropout1): Dropout(p=0.0, inplace=False)\n","            (dropout2): Dropout(p=0.0, inplace=False)\n","          )\n","          (3): TransformerEncoderLayer(\n","            (self_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n","            )\n","            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n","            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","            (dropout1): Dropout(p=0.0, inplace=False)\n","            (dropout2): Dropout(p=0.0, inplace=False)\n","          )\n","          (4): TransformerEncoderLayer(\n","            (self_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n","            )\n","            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n","            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","            (dropout1): Dropout(p=0.0, inplace=False)\n","            (dropout2): Dropout(p=0.0, inplace=False)\n","          )\n","          (5): TransformerEncoderLayer(\n","            (self_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n","            )\n","            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n","            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","            (dropout1): Dropout(p=0.0, inplace=False)\n","            (dropout2): Dropout(p=0.0, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pe_layer): PositionEmbeddingSine()\n","    (layer_4): Conv2d(\n","      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","      (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n","    )\n","  )\n","  (mask_predictor): MaskPredictor(\n","    (pe_layer): PositionEmbeddingSine()\n","    (transformer): Transformer(\n","      (encoder): TransformerEncoder(\n","        (layers): ModuleList()\n","      )\n","      (decoder): TransformerDecoder(\n","        (layers): ModuleList(\n","          (0): TransformerDecoderLayer(\n","            (self_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","            )\n","            (multihead_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","            )\n","            (linear1): Linear(in_features=128, out_features=2048, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","            (linear2): Linear(in_features=2048, out_features=128, bias=True)\n","            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (dropout1): Dropout(p=0.0, inplace=False)\n","            (dropout2): Dropout(p=0.0, inplace=False)\n","            (dropout3): Dropout(p=0.0, inplace=False)\n","          )\n","          (1): TransformerDecoderLayer(\n","            (self_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","            )\n","            (multihead_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","            )\n","            (linear1): Linear(in_features=128, out_features=2048, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","            (linear2): Linear(in_features=2048, out_features=128, bias=True)\n","            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (dropout1): Dropout(p=0.0, inplace=False)\n","            (dropout2): Dropout(p=0.0, inplace=False)\n","            (dropout3): Dropout(p=0.0, inplace=False)\n","          )\n","          (2): TransformerDecoderLayer(\n","            (self_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","            )\n","            (multihead_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","            )\n","            (linear1): Linear(in_features=128, out_features=2048, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","            (linear2): Linear(in_features=2048, out_features=128, bias=True)\n","            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (dropout1): Dropout(p=0.0, inplace=False)\n","            (dropout2): Dropout(p=0.0, inplace=False)\n","            (dropout3): Dropout(p=0.0, inplace=False)\n","          )\n","          (3): TransformerDecoderLayer(\n","            (self_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","            )\n","            (multihead_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","            )\n","            (linear1): Linear(in_features=128, out_features=2048, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","            (linear2): Linear(in_features=2048, out_features=128, bias=True)\n","            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (dropout1): Dropout(p=0.0, inplace=False)\n","            (dropout2): Dropout(p=0.0, inplace=False)\n","            (dropout3): Dropout(p=0.0, inplace=False)\n","          )\n","          (4): TransformerDecoderLayer(\n","            (self_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","            )\n","            (multihead_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","            )\n","            (linear1): Linear(in_features=128, out_features=2048, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","            (linear2): Linear(in_features=2048, out_features=128, bias=True)\n","            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (dropout1): Dropout(p=0.0, inplace=False)\n","            (dropout2): Dropout(p=0.0, inplace=False)\n","            (dropout3): Dropout(p=0.0, inplace=False)\n","          )\n","          (5): TransformerDecoderLayer(\n","            (self_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","            )\n","            (multihead_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","            )\n","            (linear1): Linear(in_features=128, out_features=2048, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","            (linear2): Linear(in_features=2048, out_features=128, bias=True)\n","            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (dropout1): Dropout(p=0.0, inplace=False)\n","            (dropout2): Dropout(p=0.0, inplace=False)\n","            (dropout3): Dropout(p=0.0, inplace=False)\n","          )\n","          (6): TransformerDecoderLayer(\n","            (self_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","            )\n","            (multihead_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","            )\n","            (linear1): Linear(in_features=128, out_features=2048, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","            (linear2): Linear(in_features=2048, out_features=128, bias=True)\n","            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (dropout1): Dropout(p=0.0, inplace=False)\n","            (dropout2): Dropout(p=0.0, inplace=False)\n","            (dropout3): Dropout(p=0.0, inplace=False)\n","          )\n","          (7): TransformerDecoderLayer(\n","            (self_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","            )\n","            (multihead_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","            )\n","            (linear1): Linear(in_features=128, out_features=2048, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","            (linear2): Linear(in_features=2048, out_features=128, bias=True)\n","            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (dropout1): Dropout(p=0.0, inplace=False)\n","            (dropout2): Dropout(p=0.0, inplace=False)\n","            (dropout3): Dropout(p=0.0, inplace=False)\n","          )\n","          (8): TransformerDecoderLayer(\n","            (self_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","            )\n","            (multihead_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","            )\n","            (linear1): Linear(in_features=128, out_features=2048, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","            (linear2): Linear(in_features=2048, out_features=128, bias=True)\n","            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (dropout1): Dropout(p=0.0, inplace=False)\n","            (dropout2): Dropout(p=0.0, inplace=False)\n","            (dropout3): Dropout(p=0.0, inplace=False)\n","          )\n","          (9): TransformerDecoderLayer(\n","            (self_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","            )\n","            (multihead_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","            )\n","            (linear1): Linear(in_features=128, out_features=2048, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","            (linear2): Linear(in_features=2048, out_features=128, bias=True)\n","            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (dropout1): Dropout(p=0.0, inplace=False)\n","            (dropout2): Dropout(p=0.0, inplace=False)\n","            (dropout3): Dropout(p=0.0, inplace=False)\n","          )\n","        )\n","        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","      )\n","    )\n","    (learnable_input_queries): Embedding(4, 128)\n","    (noise_token): Embedding(1, 128)\n","    (input_proj): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","    (ASP): ZeroShotASP(\n","      (stft): STFT(\n","        (conv_real): Conv1d(1, 1025, kernel_size=(2048,), stride=(320,), bias=False)\n","        (conv_imag): Conv1d(1, 1025, kernel_size=(2048,), stride=(320,), bias=False)\n","      )\n","      (istft): ISTFT(\n","        (conv_real): Conv1d(2048, 2048, kernel_size=(1,), stride=(1,), bias=False)\n","        (conv_imag): Conv1d(2048, 2048, kernel_size=(1,), stride=(1,), bias=False)\n","      )\n","      (bn0): BatchNorm2d(1025, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","      (encoder_block1): EncoderBlock(\n","        (conv_block): ConvBlock(\n","          (conv1): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(4, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(4, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","          (emb1): Linear(in_features=128, out_features=4, bias=True)\n","          (emb2): Linear(in_features=128, out_features=4, bias=True)\n","        )\n","      )\n","      (encoder_block2): EncoderBlock(\n","        (conv_block): ConvBlock(\n","          (conv1): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","          (emb1): Linear(in_features=128, out_features=8, bias=True)\n","          (emb2): Linear(in_features=128, out_features=8, bias=True)\n","        )\n","      )\n","      (encoder_block3): EncoderBlock(\n","        (conv_block): ConvBlock(\n","          (conv1): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","          (emb1): Linear(in_features=128, out_features=16, bias=True)\n","          (emb2): Linear(in_features=128, out_features=16, bias=True)\n","        )\n","      )\n","      (encoder_block4): EncoderBlock(\n","        (conv_block): ConvBlock(\n","          (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","          (emb1): Linear(in_features=128, out_features=32, bias=True)\n","          (emb2): Linear(in_features=128, out_features=32, bias=True)\n","        )\n","      )\n","      (conv_block7): ConvBlock(\n","        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","        (emb1): Linear(in_features=128, out_features=64, bias=True)\n","        (emb2): Linear(in_features=128, out_features=64, bias=True)\n","      )\n","      (decoder_block3): DecoderBlock(\n","        (conv1): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","        (conv_block2): ConvBlock(\n","          (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","          (emb1): Linear(in_features=128, out_features=32, bias=True)\n","          (emb2): Linear(in_features=128, out_features=32, bias=True)\n","        )\n","        (emb1): Linear(in_features=128, out_features=32, bias=True)\n","      )\n","      (decoder_block4): DecoderBlock(\n","        (conv1): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","        (conv_block2): ConvBlock(\n","          (conv1): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","          (emb1): Linear(in_features=128, out_features=16, bias=True)\n","          (emb2): Linear(in_features=128, out_features=16, bias=True)\n","        )\n","        (emb1): Linear(in_features=128, out_features=16, bias=True)\n","      )\n","      (decoder_block5): DecoderBlock(\n","        (conv1): ConvTranspose2d(16, 8, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","        (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","        (conv_block2): ConvBlock(\n","          (conv1): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","          (emb1): Linear(in_features=128, out_features=8, bias=True)\n","          (emb2): Linear(in_features=128, out_features=8, bias=True)\n","        )\n","        (emb1): Linear(in_features=128, out_features=8, bias=True)\n","      )\n","      (decoder_block6): DecoderBlock(\n","        (conv1): ConvTranspose2d(8, 4, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","        (bn1): BatchNorm2d(4, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","        (conv_block2): ConvBlock(\n","          (conv1): Conv2d(8, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(4, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(4, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","          (emb1): Linear(in_features=128, out_features=4, bias=True)\n","          (emb2): Linear(in_features=128, out_features=4, bias=True)\n","        )\n","        (emb1): Linear(in_features=128, out_features=4, bias=True)\n","      )\n","      (after_conv_block1): ConvBlock(\n","        (conv1): Conv2d(4, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(2, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(2, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","        (emb1): Linear(in_features=128, out_features=2, bias=True)\n","        (emb2): Linear(in_features=128, out_features=2, bias=True)\n","      )\n","      (after_conv2): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (VGGish): VGGish(\n","      (features): Sequential(\n","        (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): ReLU(inplace=True)\n","        (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","        (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (4): ReLU(inplace=True)\n","        (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","        (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (7): ReLU(inplace=True)\n","        (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (9): ReLU(inplace=True)\n","        (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","        (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (12): ReLU(inplace=True)\n","        (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (14): ReLU(inplace=True)\n","        (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","      )\n","      (fc): Sequential(\n","        (0): Linear(in_features=12288, out_features=4096, bias=True)\n","        (1): ReLU(inplace=True)\n","        (2): Linear(in_features=4096, out_features=4096, bias=True)\n","        (3): ReLU(inplace=True)\n","        (4): Linear(in_features=4096, out_features=128, bias=True)\n","        (5): ReLU(inplace=True)\n","      )\n","    )\n","    (mask_embed): MLP(\n","      (layers): ModuleList(\n","        (0): Linear(in_features=128, out_features=128, bias=True)\n","        (1): Linear(in_features=128, out_features=128, bias=True)\n","        (2): Linear(in_features=128, out_features=256, bias=True)\n","      )\n","      (layers4compare): ModuleList(\n","        (0): Linear(in_features=128, out_features=128, bias=True)\n","        (1): Linear(in_features=128, out_features=128, bias=True)\n","        (2): Linear(in_features=128, out_features=128, bias=True)\n","      )\n","    )\n","  )\n","  (criterion): SetCriterion()\n",")"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["trainer.model.to('cpu')"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["1258.6978569030762"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["tp = sum(p.numel() for p in trainer.model.parameters())\n","tsmb = tp * 4 / (1024 * 1024)\n","tsmb"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["mem_params = sum([param.nelement()*param.element_size() for param in trainer.model.parameters()])\n","mem_bufs = sum([buf.nelement()*buf.element_size() for buf in trainer.model.buffers()])\n","mem = mem_params + mem_bufs # in bytes"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["0.0"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["import torch \n","torch.cuda.memory_allocated('cpu')/1024 / 1024"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["trainer.train(epochs = 10)"]},{"cell_type":"markdown","metadata":{},"source":["### Trainer code"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","from tqdm import tqdm, trange\n","import torch\n","from torch import nn\n","from torch.optim import Adam, lr_scheduler\n","\n","from MODULES.AVSL_model import AVSLModel\n","\n","from DATALOADER import VideoDataLoader"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["device = torch.device(cfg.MODEL.DEVICE)\n","\n","model = AVSLModel(cfg, training=True)\n","# model.to(device)\n","model.zero_grad()\n","model.train()\n","\n","optimizer = torch.optim.Adam(\n","    model.parameters(),    # 역전파 연산을 할 모델의 파라미터\n","    lr=0.003               # 임의의 learning_rate\n",")\n","# 주어진 step 이 지날때마다 학습률(Learning Rate)을 선형으로 변환해주는 스케줄러\n","scheduler = lr_scheduler.StepLR(\n","    optimizer,             # 학습률을 조절할 optimizer\n","    step_size=100,          # 학습률을 변환할 주기 (step)\n","    gamma=0.9              # 변환할 학습률 (상대값)\n",")\n","\n","folder_path = 'DATA/videos'\n","train_dataloader = VideoDataLoader(cfg, folder_path)\n","\n","train_steps = len(train_dataloader)\n","print(train_steps)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["epochs = 10 \n","total_step = len(train_dataloader)\n","model.train()\n","\n","# epoch 루프\n","for epoch in range(epochs):\n","    \n","    # step 루프\n","    for i, batch in enumerate(train_dataloader):\n","        \n","        # 순전파 - 모델의 추론 및 결과의 loss 연산\n","        loss = model(batch)\n","        losses = torch.tensor(0)\n","        for key in loss.keys():\n","            losses = losses + loss[key]\n","\n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        losses.backward() \n","        optimizer.step()\n","\n","        print('Epoch [{}/{}], Step [{}/{}], Loss: {}'\n","              .format(epoch + 1, epochs, i + 1, total_step, loss))"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from DATALOADER import VideoDataLoader\n","\n","folder_path = 'DATA/videos'\n","train_dataloader = VideoDataLoader(cfg, folder_path)\n","print(len(train_dataloader))\n","\n","data = next(iter(train_dataloader))"]},{"cell_type":"markdown","metadata":{"id":"Sm5D6upQUAoy"},"source":["# AVSLModel"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from MODULES.AVSL_model import AVSLModel\n","\n","avsl_model = AVSLModel(cfg, training=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["outputs = avsl_model(data)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["avsl_model.criterion.weight_dict"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["outputs.keys()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for key in outputs.keys():\n","    print(key)\n","    print(outputs[key])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for key in outputs.keys():\n","    print(key)\n","    print(outputs[key])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for key in outputs.keys():\n","    print(key)\n","    print(outputs[key])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for key in outputs.keys():\n","    print(key)\n","    print(outputs[key])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# LightTrainer"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import detectron2.utils.comm as comm\n","from detectron2.config import get_cfg\n","from detectron2.projects.deeplab import add_deeplab_config\n","from detectron2.utils.logger import setup_logger\n","from MODULES.MaskFormer.config import add_mask_former_config"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Loading config MODULES/MaskFormer/configs/custom/MaskAVSL_swin_base.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.\n"]},{"data":{"text/plain":["<Logger MaskAVSL (DEBUG)>"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# Create configs and perform basic setups\n","\n","cfg = get_cfg()\n","add_deeplab_config(cfg)\n","add_mask_former_config(cfg)\n","cfg.set_new_allowed(True)\n","cfg.merge_from_file(\"MODULES/MaskFormer/configs/custom/MaskAVSL_swin_base.yaml\")\n","# cfg.merge_from_list(args.opts)\n","cfg.MODEL.DEVICE = \"cuda:2\"\n","cfg.SOLVER.IMS_PER_BATCH = 4\n","cfg.MODEL.MASK_FORMER.TRANSFORMER_IN_FEATURE = \"res5\"\n","cfg.freeze()\n","# default_setup(cfg, args)\n","# Setup logger for \"mask_former\" module\n","setup_logger(output=cfg.OUTPUT_DIR, distributed_rank=comm.get_rank(), name=\"MaskAVSL\")"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/plain":["16"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["cfg.MODEL.MASK_FORMER.NUM_OBJECT_TOKENS"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/envs/GEA/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272168290/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"]},{"name":"stdout","output_type":"stream","text":["221831 of train videos have loaded\n","7428 of train videos have loaded\n"]}],"source":["from trainer import LightTrainer\n","\n","trainer = LightTrainer(cfg)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/envs/GEA/lib/python3.7/site-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  max_size = (max_size + (stride - 1)) // stride * stride\n","/workspace/GitHub/AVSL/MODULES/MaskFormer/modeling/transformer/position_encoding.py:41: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)\n"]},{"name":"stdout","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"/workspace/GitHub/AVSL/trainer.py\", line 341, in train\n","    outputs = self.model(batch, mode='train')\n","  File \"/opt/conda/envs/GEA/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/workspace/GitHub/AVSL/MODULES/AVSL_model_light.py\", line 197, in forward\n","    outputs = self.mask_predictor(image_feature[self.transformer_in_feature], pp_embeds, mixed_audio.to(self.device))\n","  File \"/opt/conda/envs/GEA/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/workspace/GitHub/AVSL/MODULES/MaskFormer/modeling/transformer/mask_predictor_light.py\", line 191, in forward\n","    sep_result, sp = self.ASP(mixed_audio, input_tokens)\n","  File \"/opt/conda/envs/GEA/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/workspace/GitHub/AVSL/MODULES/AudioModule/LAAS.py\", line 478, in forward\n","    x = self.decoder_block4(x, x3, condition)   # (bs, 128, T / 4, F / 4)\n","  File \"/opt/conda/envs/GEA/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/workspace/GitHub/AVSL/MODULES/AudioModule/LAAS.py\", line 222, in forward\n","    x = self.conv_block2(x, condition)\n","  File \"/opt/conda/envs/GEA/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/workspace/GitHub/AVSL/MODULES/AudioModule/LAAS.py\", line 164, in forward\n","    x = act(self.bn2(self.conv2(x)), self.activation) + c2[:, :, None, None]\n","  File \"/opt/conda/envs/GEA/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/opt/conda/envs/GEA/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py\", line 179, in forward\n","    self.eps,\n","  File \"/opt/conda/envs/GEA/lib/python3.7/site-packages/torch/nn/functional.py\", line 2283, in batch_norm\n","    input, weight, bias, running_mean, running_var, training, momentum, eps, torch.backends.cudnn.enabled\n","RuntimeError: CUDA out of memory. Tried to allocate 136.00 MiB (GPU 2; 10.75 GiB total capacity; 9.11 GiB already allocated; 69.56 MiB free; 9.41 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","\n"]}],"source":["trainer.train(10)"]},{"cell_type":"markdown","metadata":{},"source":["# URMP dataset train"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import detectron2.utils.comm as comm\n","from detectron2.config import get_cfg\n","from detectron2.projects.deeplab import add_deeplab_config\n","from detectron2.utils.logger import setup_logger\n","from MODULES.MaskFormer.config import add_mask_former_config"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Loading config MODULES/MaskFormer/configs/custom/MaskAVSL_swin_base.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.\n"]},{"data":{"text/plain":["<Logger MaskAVSL (DEBUG)>"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# Create configs and perform basic setups\n","\n","cfg = get_cfg()\n","add_deeplab_config(cfg)\n","add_mask_former_config(cfg)\n","cfg.set_new_allowed(True)\n","cfg.merge_from_file(\"MODULES/MaskFormer/configs/custom/MaskAVSL_swin_base.yaml\")\n","# cfg.merge_from_list(args.opts)\n","cfg.MODEL.DEVICE = \"cuda:2\"\n","cfg.SOLVER.IMS_PER_BATCH = 1\n","cfg.MODEL.MASK_FORMER.TRANSFORMER_IN_FEATURE = \"res5\"\n","cfg.freeze()\n","# default_setup(cfg, args)\n","# Setup logger for \"mask_former\" module\n","setup_logger(output=cfg.OUTPUT_DIR, distributed_rank=comm.get_rank(), name=\"MaskAVSL\")"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/envs/GEA/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272168290/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"]},{"name":"stdout","output_type":"stream","text":["43 of evaluation videos have loaded\n"]}],"source":["from trainer import URMPTrainer\n","\n","trainer = URMPTrainer(cfg)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/envs/GEA/lib/python3.7/site-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  max_size = (max_size + (stride - 1)) // stride * stride\n","/workspace/GitHub/AVSL/MODULES/MaskFormer/modeling/transformer/position_encoding.py:41: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/1], Step [1/43], Loss: 973.6455688476562\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/envs/GEA/lib/python3.7/site-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  max_size = (max_size + (stride - 1)) // stride * stride\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_2883165/4039754494.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/workspace/GitHub/AVSL/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/envs/GEA/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/envs/GEA/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/envs/GEA/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/envs/GEA/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/workspace/GitHub/AVSL/Evaluation_DATALOADER.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Load video and extract central frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mvideo_clip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVideoFileClip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;31m# Change to random frame, loading randomly changes the frame every batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<decorator-gen-208>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, decode_file, has_mask, audio, audio_buffersize, target_resolution, resize_algorithm, audio_fps, audio_nbytes, fps_source, pix_fmt)\u001b[0m\n","\u001b[0;32m/opt/conda/envs/GEA/lib/python3.7/site-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(f, *a, **kw)\u001b[0m\n\u001b[1;32m     87\u001b[0m         ]\n\u001b[1;32m     88\u001b[0m         \u001b[0mnew_kw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvarnames\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/envs/GEA/lib/python3.7/site-packages/moviepy/video/io/VideoFileClip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, decode_file, has_mask, audio, audio_buffersize, target_resolution, resize_algorithm, audio_fps, audio_nbytes, fps_source, pix_fmt)\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0mbuffersize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maudio_buffersize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0mfps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maudio_fps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                 \u001b[0mnbytes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maudio_nbytes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m             )\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<decorator-gen-168>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, decode_file, buffersize, nbytes, fps)\u001b[0m\n","\u001b[0;32m/opt/conda/envs/GEA/lib/python3.7/site-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(f, *a, **kw)\u001b[0m\n\u001b[1;32m     87\u001b[0m         ]\n\u001b[1;32m     88\u001b[0m         \u001b[0mnew_kw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvarnames\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/envs/GEA/lib/python3.7/site-packages/moviepy/audio/io/AudioFileClip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, decode_file, buffersize, nbytes, fps)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mfps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mnbytes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mbuffersize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffersize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         )\n\u001b[1;32m     82\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/envs/GEA/lib/python3.7/site-packages/moviepy/audio/io/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, buffersize, decode_file, print_infos, fps, nbytes, nchannels)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macodec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"pcm_s%dle\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnchannels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnchannels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mffmpeg_parse_infos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"duration\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"video_duration\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minfos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/envs/GEA/lib/python3.7/site-packages/moviepy/video/io/ffmpeg_reader.py\u001b[0m in \u001b[0;36mffmpeg_parse_infos\u001b[0;34m(filename, decode_file, print_infos, check_duration, fps_source)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0mpopen_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"creationflags\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0x08000000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m     \u001b[0mproc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpopen_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf8\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/envs/GEA/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    798\u001b[0m                                 \u001b[0mc2pread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2pwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    801\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0;31m# Cleanup if the child failed starting.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/envs/GEA/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1480\u001b[0m                             \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m                             \u001b[0merrpipe_read\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrpipe_write\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m                             restore_signals, start_new_session, preexec_fn)\n\u001b[0m\u001b[1;32m   1483\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_child_created\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m                 \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["trainer.train(1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["pDe-87-15hMh"],"gpuType":"T4","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.11"}},"nbformat":4,"nbformat_minor":0}
