{"cells":[{"cell_type":"markdown","metadata":{"id":"p35qYqUBUAoj"},"source":["# Environment setup"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import detectron2.utils.comm as comm\n","from detectron2.config import get_cfg\n","from detectron2.projects.deeplab import add_deeplab_config\n","from detectron2.utils.logger import setup_logger\n","from MODULES.MaskFormer.config import add_mask_former_config"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Loading config MODULES/MaskFormer/configs/custom/MaskAVSL_swin_base.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.\n"]},{"data":{"text/plain":["<Logger MaskAVSL (DEBUG)>"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# Create configs and perform basic setups\n","\n","cfg = get_cfg()\n","add_deeplab_config(cfg)\n","add_mask_former_config(cfg)\n","cfg.set_new_allowed(True)\n","cfg.merge_from_file(\"MODULES/MaskFormer/configs/custom/MaskAVSL_swin_base.yaml\")\n","# cfg.merge_from_list(args.opts)\n","cfg.MODEL.DEVICE = \"cuda:2\"\n","cfg.SOLVER.IMS_PER_BATCH = 4\n","cfg.eval_only = False\n","cfg.freeze()\n","# default_setup(cfg, args)\n","# Setup logger for \"mask_former\" module\n","setup_logger(output=cfg.OUTPUT_DIR, distributed_rank=comm.get_rank(), name=\"MaskAVSL\")"]},{"cell_type":"markdown","metadata":{},"source":["# Trainer"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/envs/GEA/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272168290/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"]},{"name":"stdout","output_type":"stream","text":["232045 of train videos have loaded\n","43 of evaluation videos have loaded\n"]}],"source":["from trainer import Trainer\n","\n","trainer = Trainer(cfg)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":["AVSLModel(\n","  (backbone): D2SwinTransformer(\n","    (patch_embed): PatchEmbed(\n","      (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n","      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (pos_drop): Dropout(p=0.0, inplace=False)\n","    (layers): ModuleList(\n","      (0): BasicLayer(\n","        (blocks): ModuleList(\n","          (0): SwinTransformerBlock(\n","            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=128, out_features=384, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=128, out_features=128, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): Identity()\n","            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=128, out_features=512, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=512, out_features=128, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (1): SwinTransformerBlock(\n","            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=128, out_features=384, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=128, out_features=128, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): DropPath(drop_prob=0.013)\n","            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=128, out_features=512, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=512, out_features=128, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","        )\n","        (downsample): PatchMerging(\n","          (reduction): Linear(in_features=512, out_features=256, bias=False)\n","          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (1): BasicLayer(\n","        (blocks): ModuleList(\n","          (0): SwinTransformerBlock(\n","            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=256, out_features=768, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=256, out_features=256, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): DropPath(drop_prob=0.026)\n","            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=256, out_features=1024, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=1024, out_features=256, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (1): SwinTransformerBlock(\n","            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=256, out_features=768, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=256, out_features=256, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): DropPath(drop_prob=0.039)\n","            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=256, out_features=1024, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=1024, out_features=256, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","        )\n","        (downsample): PatchMerging(\n","          (reduction): Linear(in_features=1024, out_features=512, bias=False)\n","          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (2): BasicLayer(\n","        (blocks): ModuleList(\n","          (0): SwinTransformerBlock(\n","            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=512, out_features=512, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): DropPath(drop_prob=0.052)\n","            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (1): SwinTransformerBlock(\n","            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=512, out_features=512, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): DropPath(drop_prob=0.065)\n","            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (2): SwinTransformerBlock(\n","            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=512, out_features=512, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): DropPath(drop_prob=0.078)\n","            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (3): SwinTransformerBlock(\n","            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=512, out_features=512, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): DropPath(drop_prob=0.091)\n","            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (4): SwinTransformerBlock(\n","            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=512, out_features=512, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): DropPath(drop_prob=0.104)\n","            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (5): SwinTransformerBlock(\n","            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=512, out_features=512, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): DropPath(drop_prob=0.117)\n","            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (6): SwinTransformerBlock(\n","            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=512, out_features=512, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): DropPath(drop_prob=0.130)\n","            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (7): SwinTransformerBlock(\n","            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=512, out_features=512, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): DropPath(drop_prob=0.143)\n","            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (8): SwinTransformerBlock(\n","            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=512, out_features=512, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): DropPath(drop_prob=0.157)\n","            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (9): SwinTransformerBlock(\n","            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=512, out_features=512, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): DropPath(drop_prob=0.170)\n","            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (10): SwinTransformerBlock(\n","            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=512, out_features=512, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): DropPath(drop_prob=0.183)\n","            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (11): SwinTransformerBlock(\n","            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=512, out_features=512, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): DropPath(drop_prob=0.196)\n","            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (12): SwinTransformerBlock(\n","            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=512, out_features=512, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): DropPath(drop_prob=0.209)\n","            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (13): SwinTransformerBlock(\n","            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=512, out_features=512, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): DropPath(drop_prob=0.222)\n","            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (14): SwinTransformerBlock(\n","            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=512, out_features=512, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): DropPath(drop_prob=0.235)\n","            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (15): SwinTransformerBlock(\n","            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=512, out_features=512, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): DropPath(drop_prob=0.248)\n","            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (16): SwinTransformerBlock(\n","            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=512, out_features=512, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): DropPath(drop_prob=0.261)\n","            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (17): SwinTransformerBlock(\n","            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=512, out_features=512, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): DropPath(drop_prob=0.274)\n","            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","        )\n","        (downsample): PatchMerging(\n","          (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n","          (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (3): BasicLayer(\n","        (blocks): ModuleList(\n","          (0): SwinTransformerBlock(\n","            (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): DropPath(drop_prob=0.287)\n","            (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (1): SwinTransformerBlock(\n","            (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (drop_path): DropPath(drop_prob=0.300)\n","            (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","              (act): GELU()\n","              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (norm0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","    (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","    (norm3): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (pixel_decoder): TransformerEncoderPixelDecoder(\n","    (adapter_1): Conv2d(\n","      128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","      (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n","    )\n","    (layer_1): Conv2d(\n","      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","      (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n","    )\n","    (adapter_2): Conv2d(\n","      256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","      (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n","    )\n","    (layer_2): Conv2d(\n","      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","      (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n","    )\n","    (adapter_3): Conv2d(\n","      512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","      (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n","    )\n","    (layer_3): Conv2d(\n","      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","      (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n","    )\n","    (mask_features): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (input_proj): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (transformer): TransformerEncoderOnly(\n","      (encoder): TransformerEncoder(\n","        (layers): ModuleList(\n","          (0): TransformerEncoderLayer(\n","            (self_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n","            )\n","            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n","            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","            (dropout1): Dropout(p=0.0, inplace=False)\n","            (dropout2): Dropout(p=0.0, inplace=False)\n","          )\n","          (1): TransformerEncoderLayer(\n","            (self_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n","            )\n","            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n","            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","            (dropout1): Dropout(p=0.0, inplace=False)\n","            (dropout2): Dropout(p=0.0, inplace=False)\n","          )\n","          (2): TransformerEncoderLayer(\n","            (self_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n","            )\n","            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n","            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","            (dropout1): Dropout(p=0.0, inplace=False)\n","            (dropout2): Dropout(p=0.0, inplace=False)\n","          )\n","          (3): TransformerEncoderLayer(\n","            (self_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n","            )\n","            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n","            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","            (dropout1): Dropout(p=0.0, inplace=False)\n","            (dropout2): Dropout(p=0.0, inplace=False)\n","          )\n","          (4): TransformerEncoderLayer(\n","            (self_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n","            )\n","            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n","            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","            (dropout1): Dropout(p=0.0, inplace=False)\n","            (dropout2): Dropout(p=0.0, inplace=False)\n","          )\n","          (5): TransformerEncoderLayer(\n","            (self_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n","            )\n","            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n","            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","            (dropout1): Dropout(p=0.0, inplace=False)\n","            (dropout2): Dropout(p=0.0, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pe_layer): PositionEmbeddingSine()\n","    (layer_4): Conv2d(\n","      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","      (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n","    )\n","  )\n","  (mask_predictor): MaskPredictor(\n","    (pe_layer): PositionEmbeddingSine()\n","    (transformer): Transformer(\n","      (encoder): TransformerEncoder(\n","        (layers): ModuleList()\n","      )\n","      (decoder): TransformerDecoder(\n","        (layers): ModuleList(\n","          (0): TransformerDecoderLayer(\n","            (self_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","            )\n","            (multihead_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","            )\n","            (linear1): Linear(in_features=128, out_features=2048, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","            (linear2): Linear(in_features=2048, out_features=128, bias=True)\n","            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (dropout1): Dropout(p=0.0, inplace=False)\n","            (dropout2): Dropout(p=0.0, inplace=False)\n","            (dropout3): Dropout(p=0.0, inplace=False)\n","          )\n","          (1): TransformerDecoderLayer(\n","            (self_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","            )\n","            (multihead_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","            )\n","            (linear1): Linear(in_features=128, out_features=2048, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","            (linear2): Linear(in_features=2048, out_features=128, bias=True)\n","            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (dropout1): Dropout(p=0.0, inplace=False)\n","            (dropout2): Dropout(p=0.0, inplace=False)\n","            (dropout3): Dropout(p=0.0, inplace=False)\n","          )\n","          (2): TransformerDecoderLayer(\n","            (self_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","            )\n","            (multihead_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","            )\n","            (linear1): Linear(in_features=128, out_features=2048, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","            (linear2): Linear(in_features=2048, out_features=128, bias=True)\n","            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (dropout1): Dropout(p=0.0, inplace=False)\n","            (dropout2): Dropout(p=0.0, inplace=False)\n","            (dropout3): Dropout(p=0.0, inplace=False)\n","          )\n","          (3): TransformerDecoderLayer(\n","            (self_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","            )\n","            (multihead_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","            )\n","            (linear1): Linear(in_features=128, out_features=2048, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","            (linear2): Linear(in_features=2048, out_features=128, bias=True)\n","            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (dropout1): Dropout(p=0.0, inplace=False)\n","            (dropout2): Dropout(p=0.0, inplace=False)\n","            (dropout3): Dropout(p=0.0, inplace=False)\n","          )\n","          (4): TransformerDecoderLayer(\n","            (self_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","            )\n","            (multihead_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","            )\n","            (linear1): Linear(in_features=128, out_features=2048, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","            (linear2): Linear(in_features=2048, out_features=128, bias=True)\n","            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (dropout1): Dropout(p=0.0, inplace=False)\n","            (dropout2): Dropout(p=0.0, inplace=False)\n","            (dropout3): Dropout(p=0.0, inplace=False)\n","          )\n","          (5): TransformerDecoderLayer(\n","            (self_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","            )\n","            (multihead_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","            )\n","            (linear1): Linear(in_features=128, out_features=2048, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","            (linear2): Linear(in_features=2048, out_features=128, bias=True)\n","            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (dropout1): Dropout(p=0.0, inplace=False)\n","            (dropout2): Dropout(p=0.0, inplace=False)\n","            (dropout3): Dropout(p=0.0, inplace=False)\n","          )\n","          (6): TransformerDecoderLayer(\n","            (self_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","            )\n","            (multihead_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","            )\n","            (linear1): Linear(in_features=128, out_features=2048, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","            (linear2): Linear(in_features=2048, out_features=128, bias=True)\n","            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (dropout1): Dropout(p=0.0, inplace=False)\n","            (dropout2): Dropout(p=0.0, inplace=False)\n","            (dropout3): Dropout(p=0.0, inplace=False)\n","          )\n","          (7): TransformerDecoderLayer(\n","            (self_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","            )\n","            (multihead_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","            )\n","            (linear1): Linear(in_features=128, out_features=2048, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","            (linear2): Linear(in_features=2048, out_features=128, bias=True)\n","            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (dropout1): Dropout(p=0.0, inplace=False)\n","            (dropout2): Dropout(p=0.0, inplace=False)\n","            (dropout3): Dropout(p=0.0, inplace=False)\n","          )\n","          (8): TransformerDecoderLayer(\n","            (self_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","            )\n","            (multihead_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","            )\n","            (linear1): Linear(in_features=128, out_features=2048, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","            (linear2): Linear(in_features=2048, out_features=128, bias=True)\n","            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (dropout1): Dropout(p=0.0, inplace=False)\n","            (dropout2): Dropout(p=0.0, inplace=False)\n","            (dropout3): Dropout(p=0.0, inplace=False)\n","          )\n","          (9): TransformerDecoderLayer(\n","            (self_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","            )\n","            (multihead_attn): MultiheadAttention(\n","              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","            )\n","            (linear1): Linear(in_features=128, out_features=2048, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","            (linear2): Linear(in_features=2048, out_features=128, bias=True)\n","            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","            (dropout1): Dropout(p=0.0, inplace=False)\n","            (dropout2): Dropout(p=0.0, inplace=False)\n","            (dropout3): Dropout(p=0.0, inplace=False)\n","          )\n","        )\n","        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","      )\n","    )\n","    (learnable_input_queries): Embedding(4, 128)\n","    (noise_token): Embedding(1, 128)\n","    (input_proj): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","    (ASP): ZeroShotASP(\n","      (stft): STFT(\n","        (conv_real): Conv1d(1, 1025, kernel_size=(2048,), stride=(320,), bias=False)\n","        (conv_imag): Conv1d(1, 1025, kernel_size=(2048,), stride=(320,), bias=False)\n","      )\n","      (istft): ISTFT(\n","        (conv_real): Conv1d(2048, 2048, kernel_size=(1,), stride=(1,), bias=False)\n","        (conv_imag): Conv1d(2048, 2048, kernel_size=(1,), stride=(1,), bias=False)\n","      )\n","      (bn0): BatchNorm2d(1025, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","      (encoder_block1): EncoderBlock(\n","        (conv_block): ConvBlock(\n","          (conv1): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(4, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(4, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","          (emb1): Linear(in_features=128, out_features=4, bias=True)\n","          (emb2): Linear(in_features=128, out_features=4, bias=True)\n","        )\n","      )\n","      (encoder_block2): EncoderBlock(\n","        (conv_block): ConvBlock(\n","          (conv1): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","          (emb1): Linear(in_features=128, out_features=8, bias=True)\n","          (emb2): Linear(in_features=128, out_features=8, bias=True)\n","        )\n","      )\n","      (encoder_block3): EncoderBlock(\n","        (conv_block): ConvBlock(\n","          (conv1): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","          (emb1): Linear(in_features=128, out_features=16, bias=True)\n","          (emb2): Linear(in_features=128, out_features=16, bias=True)\n","        )\n","      )\n","      (encoder_block4): EncoderBlock(\n","        (conv_block): ConvBlock(\n","          (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","          (emb1): Linear(in_features=128, out_features=32, bias=True)\n","          (emb2): Linear(in_features=128, out_features=32, bias=True)\n","        )\n","      )\n","      (conv_block7): ConvBlock(\n","        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","        (emb1): Linear(in_features=128, out_features=64, bias=True)\n","        (emb2): Linear(in_features=128, out_features=64, bias=True)\n","      )\n","      (decoder_block3): DecoderBlock(\n","        (conv1): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","        (conv_block2): ConvBlock(\n","          (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","          (emb1): Linear(in_features=128, out_features=32, bias=True)\n","          (emb2): Linear(in_features=128, out_features=32, bias=True)\n","        )\n","        (emb1): Linear(in_features=128, out_features=32, bias=True)\n","      )\n","      (decoder_block4): DecoderBlock(\n","        (conv1): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","        (conv_block2): ConvBlock(\n","          (conv1): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","          (emb1): Linear(in_features=128, out_features=16, bias=True)\n","          (emb2): Linear(in_features=128, out_features=16, bias=True)\n","        )\n","        (emb1): Linear(in_features=128, out_features=16, bias=True)\n","      )\n","      (decoder_block5): DecoderBlock(\n","        (conv1): ConvTranspose2d(16, 8, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","        (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","        (conv_block2): ConvBlock(\n","          (conv1): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","          (emb1): Linear(in_features=128, out_features=8, bias=True)\n","          (emb2): Linear(in_features=128, out_features=8, bias=True)\n","        )\n","        (emb1): Linear(in_features=128, out_features=8, bias=True)\n","      )\n","      (decoder_block6): DecoderBlock(\n","        (conv1): ConvTranspose2d(8, 4, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","        (bn1): BatchNorm2d(4, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","        (conv_block2): ConvBlock(\n","          (conv1): Conv2d(8, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(4, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(4, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","          (emb1): Linear(in_features=128, out_features=4, bias=True)\n","          (emb2): Linear(in_features=128, out_features=4, bias=True)\n","        )\n","        (emb1): Linear(in_features=128, out_features=4, bias=True)\n","      )\n","      (after_conv_block1): ConvBlock(\n","        (conv1): Conv2d(4, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(2, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(2, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n","        (emb1): Linear(in_features=128, out_features=2, bias=True)\n","        (emb2): Linear(in_features=128, out_features=2, bias=True)\n","      )\n","      (after_conv2): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (VGGish): VGGish(\n","      (features): Sequential(\n","        (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): ReLU(inplace=True)\n","        (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","        (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (4): ReLU(inplace=True)\n","        (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","        (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (7): ReLU(inplace=True)\n","        (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (9): ReLU(inplace=True)\n","        (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","        (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (12): ReLU(inplace=True)\n","        (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (14): ReLU(inplace=True)\n","        (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","      )\n","      (fc): Sequential(\n","        (0): Linear(in_features=12288, out_features=4096, bias=True)\n","        (1): ReLU(inplace=True)\n","        (2): Linear(in_features=4096, out_features=4096, bias=True)\n","        (3): ReLU(inplace=True)\n","        (4): Linear(in_features=4096, out_features=128, bias=True)\n","        (5): ReLU(inplace=True)\n","      )\n","    )\n","    (mask_embed): MLP(\n","      (layers): ModuleList(\n","        (0): Linear(in_features=128, out_features=128, bias=True)\n","        (1): Linear(in_features=128, out_features=128, bias=True)\n","        (2): Linear(in_features=128, out_features=256, bias=True)\n","      )\n","      (layers4compare): ModuleList(\n","        (0): Linear(in_features=128, out_features=128, bias=True)\n","        (1): Linear(in_features=128, out_features=128, bias=True)\n","        (2): Linear(in_features=128, out_features=128, bias=True)\n","      )\n","    )\n","  )\n","  (criterion): SetCriterion()\n",")"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["trainer.model.to('cpu')"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["1258.6978569030762"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["tp = sum(p.numel() for p in trainer.model.parameters())\n","tsmb = tp * 4 / (1024 * 1024)\n","tsmb"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["mem_params = sum([param.nelement()*param.element_size() for param in trainer.model.parameters()])\n","mem_bufs = sum([buf.nelement()*buf.element_size() for buf in trainer.model.buffers()])\n","mem = mem_params + mem_bufs # in bytes"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["0.0"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["import torch \n","torch.cuda.memory_allocated('cpu')/1024 / 1024"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["trainer.train(epochs = 10)"]},{"cell_type":"markdown","metadata":{},"source":["### Trainer code"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","from tqdm import tqdm, trange\n","import torch\n","from torch import nn\n","from torch.optim import Adam, lr_scheduler\n","\n","from MODULES.AVSL_model import AVSLModel\n","\n","from DATALOADER import VideoDataLoader"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["device = torch.device(cfg.MODEL.DEVICE)\n","\n","model = AVSLModel(cfg, training=True)\n","# model.to(device)\n","model.zero_grad()\n","model.train()\n","\n","optimizer = torch.optim.Adam(\n","    model.parameters(),    # 역전파 연산을 할 모델의 파라미터\n","    lr=0.003               # 임의의 learning_rate\n",")\n","# 주어진 step 이 지날때마다 학습률(Learning Rate)을 선형으로 변환해주는 스케줄러\n","scheduler = lr_scheduler.StepLR(\n","    optimizer,             # 학습률을 조절할 optimizer\n","    step_size=100,          # 학습률을 변환할 주기 (step)\n","    gamma=0.9              # 변환할 학습률 (상대값)\n",")\n","\n","folder_path = 'DATA/videos'\n","train_dataloader = VideoDataLoader(cfg, folder_path)\n","\n","train_steps = len(train_dataloader)\n","print(train_steps)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["epochs = 10 \n","total_step = len(train_dataloader)\n","model.train()\n","\n","# epoch 루프\n","for epoch in range(epochs):\n","    \n","    # step 루프\n","    for i, batch in enumerate(train_dataloader):\n","        \n","        # 순전파 - 모델의 추론 및 결과의 loss 연산\n","        loss = model(batch)\n","        losses = torch.tensor(0)\n","        for key in loss.keys():\n","            losses = losses + loss[key]\n","\n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        losses.backward() \n","        optimizer.step()\n","\n","        print('Epoch [{}/{}], Step [{}/{}], Loss: {}'\n","              .format(epoch + 1, epochs, i + 1, total_step, loss))"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from DATALOADER import VideoDataLoader\n","\n","folder_path = 'DATA/videos'\n","train_dataloader = VideoDataLoader(cfg, folder_path)\n","print(len(train_dataloader))\n","\n","data = next(iter(train_dataloader))"]},{"cell_type":"markdown","metadata":{"id":"Sm5D6upQUAoy"},"source":["# AVSLModel"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from MODULES.AVSL_model import AVSLModel\n","\n","avsl_model = AVSLModel(cfg, training=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["outputs = avsl_model(data)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["avsl_model.criterion.weight_dict"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["outputs.keys()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for key in outputs.keys():\n","    print(key)\n","    print(outputs[key])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for key in outputs.keys():\n","    print(key)\n","    print(outputs[key])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for key in outputs.keys():\n","    print(key)\n","    print(outputs[key])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for key in outputs.keys():\n","    print(key)\n","    print(outputs[key])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# LightTrainer"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Loading config MODULES/MaskFormer/configs/custom/MaskAVSL_swin_base.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.\n"]},{"data":{"text/plain":["<Logger MaskAVSL (DEBUG)>"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# Create configs and perform basic setups\n","\n","cfg = get_cfg()\n","add_deeplab_config(cfg)\n","add_mask_former_config(cfg)\n","cfg.set_new_allowed(True)\n","cfg.merge_from_file(\"MODULES/MaskFormer/configs/custom/MaskAVSL_swin_base.yaml\")\n","# cfg.merge_from_list(args.opts)\n","cfg.MODEL.DEVICE = \"cuda:1\"\n","cfg.SOLVER.IMS_PER_BATCH = 4\n","cfg.MODEL.MASK_FORMER.TRANSFORMER_IN_FEATURE = \"res5\"\n","cfg.freeze()\n","# default_setup(cfg, args)\n","# Setup logger for \"mask_former\" module\n","setup_logger(output=cfg.OUTPUT_DIR, distributed_rank=comm.get_rank(), name=\"MaskAVSL\")"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/envs/GEA/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272168290/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"]},{"name":"stdout","output_type":"stream","text":["221831 of train videos have loaded\n"]}],"source":["from trainer import LightTrainer\n","\n","trainer = LightTrainer(cfg)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/envs/GEA/lib/python3.7/site-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  max_size = (max_size + (stride - 1)) // stride * stride\n","/workspace/GitHub/AVSL/MODULES/MaskFormer/modeling/transformer/position_encoding.py:41: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)\n"]},{"ename":"RuntimeError","evalue":"Given groups=1, weight of size [128, 256, 1, 1], expected input[4, 1024, 20, 20] to have 256 channels, but got 1024 channels instead","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_575572/2822347328.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/workspace/GitHub/AVSL/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m                 \u001b[0mas_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAS_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mixed_audio_spec\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sep_audio_specs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/envs/GEA/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/workspace/GitHub/AVSL/MODULES/AVSL_model_light.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batched_inputs, mode, visualization)\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0;31m# pp_embeds, image_features = self.pixel_decoder(features=image_feature)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0mpp_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_feature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_in_feature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpp_embeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmixed_audio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/envs/GEA/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/workspace/GitHub/AVSL/MODULES/MaskFormer/modeling/transformer/mask_predictor_light.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, pp_embeds, mixed_audio, mode)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearnable_input_queries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0;31m################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/envs/GEA/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/envs/GEA/lib/python3.7/site-packages/detectron2/layers/wrappers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         x = F.conv2d(\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         )\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [128, 256, 1, 1], expected input[4, 1024, 20, 20] to have 256 channels, but got 1024 channels instead"]}],"source":["trainer.train(10)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["pDe-87-15hMh"],"gpuType":"T4","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.11"}},"nbformat":4,"nbformat_minor":0}
