{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Audio Separation Loss**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\mathcal{L}_{AS} = \\sum_f^{all frames}(\\sum_n^{N+1}  A_{{sep}_{n,i}} - A_{{ori}_i})^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### AS Loss\n",
    "def AS_loss(audio_gt, audio_sp):\n",
    "    loss = 0\n",
    "    for x in range(len(audio_gt)):\n",
    "        sp_sum = 0\n",
    "        for i in range(audio_sp.shape[0]):\n",
    "            sp_sum += audio_sp[i][x]\n",
    "        loss += (sp_sum - audio_gt[x])**2\n",
    "    return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Less Separation Loss**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ hann\\_func(x) := 종 모양 func$$\n",
    "\n",
    "spectral flatness * power 가 0 혹은 1에 가까울 때 손실률이 0에 가까워지게"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LS Loss\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "def hann_func(x):\n",
    "    return 0.5 * (1 - np.cos(2 * np.pi * x))\n",
    "\"\"\"\n",
    "def power_to_db(\n",
    "    S: _ScalarOrSequence[_ComplexLike_co],\n",
    "    *,\n",
    "    ref: Union[float, Callable] = 1.0,\n",
    "    amin: float = 1e-10,\n",
    "    top_db: Optional[float] = 80.0,\n",
    ") -> Union[np.floating[Any], np.ndarray]:\n",
    "    \"\"\"\n",
    "    \"\"\"Convert a power spectrogram (amplitude squared) to decibel (dB) units\n",
    "\n",
    "    This computes the scaling ``10 * log10(S / ref)`` in a numerically\n",
    "    stable way.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    S : np.ndarray\n",
    "        input power\n",
    "\n",
    "    ref : scalar or callable\n",
    "        If scalar, the amplitude ``abs(S)`` is scaled relative to ``ref``::\n",
    "\n",
    "            10 * log10(S / ref)\n",
    "\n",
    "        Zeros in the output correspond to positions where ``S == ref``.\n",
    "\n",
    "        If callable, the reference value is computed as ``ref(S)``.\n",
    "\n",
    "    amin : float > 0 [scalar]\n",
    "        minimum threshold for ``abs(S)`` and ``ref``\n",
    "\n",
    "    top_db : float >= 0 [scalar]\n",
    "        threshold the output at ``top_db`` below the peak:\n",
    "        ``max(10 * log10(S/ref)) - top_db``\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    S_db : np.ndarray\n",
    "        ``S_db ~= 10 * log10(S) - 10 * log10(ref)``\n",
    "\n",
    "    See Also\n",
    "    --------\n",
    "    perceptual_weighting\n",
    "    db_to_power\n",
    "    amplitude_to_db\n",
    "    db_to_amplitude\n",
    "    Notes\n",
    "    -----\n",
    "    This function caches at level 30.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    Get a power spectrogram from a waveform ``y``\n",
    "\n",
    "    >>> y, sr = librosa.load(librosa.ex('trumpet'))\n",
    "    >>> S = np.abs(librosa.stft(y))\n",
    "    >>> librosa.power_to_db(S**2)\n",
    "    array([[-41.809, -41.809, ..., -41.809, -41.809],\n",
    "           [-41.809, -41.809, ..., -41.809, -41.809],\n",
    "           ...,\n",
    "           [-41.809, -41.809, ..., -41.809, -41.809],\n",
    "           [-41.809, -41.809, ..., -41.809, -41.809]], dtype=float32)\n",
    "\n",
    "    Compute dB relative to peak power\n",
    "\n",
    "    >>> librosa.power_to_db(S**2, ref=np.max)\n",
    "    array([[-80., -80., ..., -80., -80.],\n",
    "           [-80., -80., ..., -80., -80.],\n",
    "           ...,\n",
    "           [-80., -80., ..., -80., -80.],\n",
    "           [-80., -80., ..., -80., -80.]], dtype=float32)\n",
    "\n",
    "    Or compare to median power\n",
    "\n",
    "    >>> librosa.power_to_db(S**2, ref=np.median)\n",
    "    array([[16.578, 16.578, ..., 16.578, 16.578],\n",
    "           [16.578, 16.578, ..., 16.578, 16.578],\n",
    "           ...,\n",
    "           [16.578, 16.578, ..., 16.578, 16.578],\n",
    "           [16.578, 16.578, ..., 16.578, 16.578]], dtype=float32)\n",
    "\n",
    "    And plot the results\n",
    "    >>> import matplotlib.pyplot as plt\n",
    "    >>> fig, ax = plt.subplots(nrows=2, sharex=True, sharey=True)\n",
    "    >>> imgpow = librosa.display.specshow(S**2, sr=sr, y_axis='log', x_axis='time',\n",
    "    ...                                   ax=ax[0])\n",
    "    >>> ax[0].set(title='Power spectrogram')\n",
    "    >>> ax[0].label_outer()\n",
    "    >>> imgdb = librosa.display.specshow(librosa.power_to_db(S**2, ref=np.max),\n",
    "    ...                                  sr=sr, y_axis='log', x_axis='time', ax=ax[1])\n",
    "    >>> ax[1].set(title='Log-Power spectrogram')\n",
    "    >>> fig.colorbar(imgpow, ax=ax[0])\n",
    "    >>> fig.colorbar(imgdb, ax=ax[1], format=\"%+2.0f dB\")\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    S = np.asarray(S)\n",
    "\n",
    "    if amin <= 0:\n",
    "        raise ParameterError(\"amin must be strictly positive\")\n",
    "\n",
    "    if np.issubdtype(S.dtype, np.complexfloating):\n",
    "        warnings.warn(\n",
    "            \"power_to_db was called on complex input so phase \"\n",
    "            \"information will be discarded. To suppress this warning, \"\n",
    "            \"call power_to_db(np.abs(D)**2) instead.\",\n",
    "            stacklevel=2,\n",
    "        )\n",
    "        magnitude = np.abs(S)\n",
    "    else:\n",
    "        magnitude = S\n",
    "\n",
    "    if callable(ref):\n",
    "        # User supplied a function to calculate reference power\n",
    "        ref_value = ref(magnitude)\n",
    "    else:\n",
    "        ref_value = np.abs(ref)\n",
    "\n",
    "    log_spec: np.ndarray = 10.0 * np.log10(np.maximum(amin, magnitude))\n",
    "    log_spec -= 10.0 * np.log10(np.maximum(amin, ref_value))\n",
    "\n",
    "    if top_db is not None:\n",
    "        if top_db < 0:\n",
    "            raise ParameterError(\"top_db must be non-negative\")\n",
    "        log_spec = np.maximum(log_spec, log_spec.max() - top_db)\n",
    "\n",
    "    return log_spec\n",
    "\"\"\"\n",
    "\n",
    "def LS_loss(x):\n",
    "    \"\"\"\n",
    "    sf: spectral_flatness of the audio \n",
    "    p: power of the audio\n",
    "    \"\"\"\n",
    "    sf = spectral_flatness(x)\n",
    "    p = power_to_db(x)\n",
    "    y = sf * p\n",
    "    return hann_func(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Audio Dominance Loss**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\mathcal{L}_{AD} = \\sum_{n=1}^N (-\\log{spectral\\_flatness(A_{sep_n})}) \\cdot \\frac{\\langle [max\\_pooling({AF}_n)] \\cdot D_n \\rangle}{\\Vert [max\\_pooling({AF}_n)] \\Vert \\cdot \\Vert D_n \\Vert}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def spectral_flatness(\n",
    "    *,\n",
    "    y: Optional[np.ndarray] = None,\n",
    "    S: Optional[np.ndarray] = None,\n",
    "    n_fft: int = 2048,\n",
    "    hop_length: int = 512,\n",
    "    win_length: Optional[int] = None,\n",
    "    window: _WindowSpec = \"hann\",\n",
    "    center: bool = True,\n",
    "    pad_mode: _PadModeSTFT = \"constant\",\n",
    "    amin: float = 1e-10,\n",
    "    power: float = 2.0,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Compute spectral flatness\n",
    "\n",
    "    Spectral flatness (or tonality coefficient) is a measure to\n",
    "    quantify how much noise-like a sound is, as opposed to being\n",
    "    tone-like [#]_. A high spectral flatness (closer to 1.0)\n",
    "    indicates the spectrum is similar to white noise.\n",
    "    It is often converted to decibel.\n",
    "\n",
    "    .. [#] Dubnov, Shlomo  \"Generalization of spectral flatness\n",
    "           measure for non-gaussian linear processes\"\n",
    "           IEEE Signal Processing Letters, 2004, Vol. 11.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : np.ndarray [shape=(..., n)] or None\n",
    "        audio time series. Multi-channel is supported.\n",
    "    S : np.ndarray [shape=(..., d, t)] or None\n",
    "        (optional) pre-computed spectrogram magnitude\n",
    "    n_fft : int > 0 [scalar]\n",
    "        FFT window size\n",
    "    hop_length : int > 0 [scalar]\n",
    "        hop length for STFT. See `librosa.stft` for details.\n",
    "    win_length : int <= n_fft [scalar]\n",
    "        Each frame of audio is windowed by `window()`.\n",
    "        The window will be of length `win_length` and then padded\n",
    "        with zeros to match ``n_fft``.\n",
    "        If unspecified, defaults to ``win_length = n_fft``.\n",
    "    window : string, tuple, number, function, or np.ndarray [shape=(n_fft,)]\n",
    "        - a window specification (string, tuple, or number);\n",
    "          see `scipy.signal.get_window`\n",
    "        - a window function, such as `scipy.signal.windows.hann`\n",
    "        - a vector or array of length ``n_fft``\n",
    "        .. see also:: `librosa.filters.get_window`\n",
    "    center : boolean\n",
    "        - If `True`, the signal ``y`` is padded so that frame\n",
    "          ``t`` is centered at ``y[t * hop_length]``.\n",
    "        - If `False`, then frame `t` begins at ``y[t * hop_length]``\n",
    "    pad_mode : string\n",
    "        If ``center=True``, the padding mode to use at the edges of the signal.\n",
    "        By default, STFT uses zero padding.\n",
    "    amin : float > 0 [scalar]\n",
    "        minimum threshold for ``S`` (=added noise floor for numerical stability)\n",
    "    power : float > 0 [scalar]\n",
    "        Exponent for the magnitude spectrogram.\n",
    "        e.g., 1 for energy, 2 for power, etc.\n",
    "        Power spectrogram is usually used for computing spectral flatness.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    flatness : np.ndarray [shape=(..., 1, t)]\n",
    "        spectral flatness for each frame.\n",
    "        The returned value is in [0, 1] and often converted to dB scale.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    From time-series input\n",
    "\n",
    "    >>> y, sr = librosa.load(librosa.ex('trumpet'))\n",
    "    >>> flatness = librosa.feature.spectral_flatness(y=y)\n",
    "    >>> flatness\n",
    "    array([[0.001, 0.   , ..., 0.218, 0.184]], dtype=float32)\n",
    "\n",
    "    From spectrogram input\n",
    "\n",
    "    >>> S, phase = librosa.magphase(librosa.stft(y))\n",
    "    >>> librosa.feature.spectral_flatness(S=S)\n",
    "    array([[0.001, 0.   , ..., 0.218, 0.184]], dtype=float32)\n",
    "\n",
    "    From power spectrogram input\n",
    "\n",
    "    >>> S, phase = librosa.magphase(librosa.stft(y))\n",
    "    >>> S_power = S ** 2\n",
    "    >>> librosa.feature.spectral_flatness(S=S_power, power=1.0)\n",
    "    array([[0.001, 0.   , ..., 0.218, 0.184]], dtype=float32)\n",
    "\n",
    "    \"\"\"\n",
    "    if amin <= 0:\n",
    "        raise ParameterError(\"amin must be strictly positive\")\n",
    "\n",
    "    S, n_fft = _spectrogram(\n",
    "        y=y,\n",
    "        S=S,\n",
    "        n_fft=n_fft,\n",
    "        hop_length=hop_length,\n",
    "        power=1.0,\n",
    "        win_length=win_length,\n",
    "        window=window,\n",
    "        center=center,\n",
    "        pad_mode=pad_mode,\n",
    "    )\n",
    "\n",
    "    if not np.isrealobj(S):\n",
    "        raise ParameterError(\n",
    "            \"Spectral flatness is only defined \" \"with real-valued input\"\n",
    "        )\n",
    "    elif np.any(S < 0):\n",
    "        raise ParameterError(\n",
    "            \"Spectral flatness is only defined \" \"with non-negative energies\"\n",
    "        )\n",
    "\n",
    "    S_thresh = np.maximum(amin, S**power)\n",
    "    gmean = np.exp(np.mean(np.log(S_thresh), axis=-2, keepdims=True))\n",
    "    amean = np.mean(S_thresh, axis=-2, keepdims=True)\n",
    "    flatness: np.ndarray = gmean / amean\n",
    "    return flatness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from math import log\n",
    "def cos_sim(a,b):\n",
    "    return dot(a,b)/(norm(a) * norm(b))\n",
    "\n",
    "def AD_loss(N, audio_features, audio_sp, D):\n",
    "    loss = 0\n",
    "    for n in range(len(N)):\n",
    "        loss +=  -log(spectral_flatness(audio_sp[n]))* cos_sim(np.max(audio_features[n], axis=1), D[n])\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scoremap Loss**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\mathcal{L}_{Sm} = -\\log \\frac{{MAX}(Score_{u,v})}{\\sum^{N,H,W}_{m,u,v}Score_{m,u,v}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sm_loss(N,n_scoremap):\n",
    "    loss = 0\n",
    "    for u in range(len(n_scoremap.shape[1])):\n",
    "        for v in range(len(n_scoremap.shape[2])):\n",
    "            loss += np.max(n_scoremap, axis=0)[u][v]/np.sum(n_scoremap, axis=0)[u][v]\n",
    "    return -log(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Contrastive Loss**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./IMGs/Clip_Fig1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a batch of N (image, text) pairs, CLIP is trained to predict which of the N × N possible (image, text) pairings across a batch actually occurred. To do this, CLIP learns a multi-modal embedding space by jointly training an image encoder and text encoder to maximize the cosine similarity of the image and text embeddings of the N real pairs in the batch while minimizing the cosine similarity of the embeddings of the N2 − N incorrect pairings. We optimize a symmetric cross entropy loss over these similarity scores. In Figure 3 we include pseudocode of the core of an implementation of CLIP. \\\\\n",
    "\n",
    "<!-- <img src = \"./IMGs/Clip_Fig2.png\">{width=\"50%\"} -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Pos : S_{i\\rightarrow i} = avg(per\\_pixel\\_embedding_i \\cdot mask\\_embedding_i) \\\\ .\n",
    "\\\\\n",
    "Neg : S_{i\\rightarrow j} = avg(per\\_pixel\\_embedding_i \\cdot mask\\_embedding_j) \\\\ . \\\\\n",
    "\\mathcal{L}_{C} = \n",
    "$$\n",
    "\n",
    "6분 35초 참조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(logits: torch.Tensor) -> torch.Tensor:\n",
    "    return nn.functional.cross_entropy(logits, torch.arange(len(logits), device=logits.device))\n",
    "\n",
    "def clip_loss(mask_embedding: torch.Tensor, mask_features: torch.Tensor, batch_size) -> torch.Tensor:\n",
    "    logit_scores = torch.zeros((batch_size, batch_size))\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        for j in range(batch_size):\n",
    "          mask_outputs = torch.einsum(\"bqc,bchw->bqhw\", mask_embedding[j].unsqueeze(0), mask_features[i].unsqueeze(0))\n",
    "          score = mask_outputs.sum()\n",
    "          logit_scores[i][j] = score\n",
    "\n",
    "    logit_scores = logit_scores / logit_scores.norm(p=1, dim=-1, keepdim=True)\n",
    "\n",
    "    feature_loss = contrastive_loss(logit_scores)\n",
    "    embed_loss = contrastive_loss(logit_scores.t())\n",
    "    return (feature_loss + embed_loss) / 2.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cid2rch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
